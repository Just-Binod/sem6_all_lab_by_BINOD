
lab 1

#simple linear regression lab :
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LinearRegression


#dataset
x = np.array([5,15,25,35,45,55]).reshape((-1,1))#reshape funcn 2 d ma lagna lai
y = np.array([5,20,14,32,22,38])




x.shape #to check the shape



from sklearn.linear_model import LinearRegression
model=LinearRegression() #creating model

#training model ( fit)
model.fit(x,y)

#print intercept and coefficient
print(model.intercept_)
print(model.coef_) #slope


print(f"y={model.intercept_ :.2f} + {model.coef_[0]}x") # y=mx+c

#predict
y_pred=model.predict(x)
y,y_pred #actual vs predicted

#using regression matrix
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
print(f"MAE={mean_absolute_error(y,y_pred):.2f}")#actual vs predicted ko MAE
print(f"MSE={mean_squared_error(y,y_pred):.2f}")#actual vs predicted ko MsE
print(f"r2={r2_score(y,y_pred):.2f}")#actual vs predicted ko r2


#plot garna #scatter data print garna lai ho
plt.scatter(x,y)
plt.plot(x,y_pred,color='violet' ,label='regression line')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Linear Regression')
plt.legend()
plt.show()










lab 2

import numpy as np
import pandas as pd
import matplotlib as plt
import matplotlib.pyplot as plt#scatter funcn use garna



#load file
from google.colab import files
uploaded = files.upload()


# read data set
salary_dataset = pd.read_csv("Salary_Data.csv")
salary_dataset.shape#size row and colm
salary_dataset.head()#top 5 value print garna
salary_dataset.tail()#last 5 value print garna



x = salary_dataset.iloc[:,0].values.reshape(-1,1)#first colm
y = salary_dataset.iloc[:,1].values.reshape(-1,1)#second colm
x,y

# safe method

# x = salary_dataset.iloc["YearsExperience"].values
# y = salary_dataset.iloc["Salary"].values
# x,y



# create model
from sklearn.linear_model import LinearRegression
model=LinearRegression() #creating model

# train or fit a model
model.fit(x,y)


#predict
y_pred=model.predict(x)
y,y_pred #actual vs predicted



#model evaluation
#using regression matrix
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score
print(f"MAE={mean_absolute_error(y,y_pred):.2f}")#actual vs predicted ko MAE
print(f"MSE={mean_squared_error(y,y_pred):.2f}")#actual vs predicted ko MsE
print(f"r2={r2_score(y,y_pred):.2f}")#actual vs predicted ko r2




#plot garna #scatter data print garna lai ho
plt.scatter(x,y ,color='red')
plt.plot(x,y_pred,color='black' ,label='regression line')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Linear Regression')
plt.legend()
plt.show()


















lab 3

#multiple linear regression using housing data,
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing #dataset
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# load dta set
housing = fetch_california_housing()

#convert to data frame
df = pd.DataFrame(housing.data, columns=housing.feature_names)
df['target'] = housing.target #target
df.head()

#features and target

X = df.drop('target', axis=1) #drop column except target #features
y = df['target'] #target

#train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# model create
model = LinearRegression()

# model train
model.fit(X_train, y_train)

# prediction
y_pred = model.predict(X_test)
y,y_pred

#evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')


# plotting
plt.scatter(y_test, y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2 ,color='yellow')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs. Predicted Values')
plt.show()

  output :
















